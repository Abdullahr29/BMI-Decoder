{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "data = scio.loadmat('monkeydata_training.mat')\n",
    "trials = data['trial'].reshape(100,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN - Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,num_layers,layer_size):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.conv = nn.Conv1d(98,20,kernel_size=1,padding='same') \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.flat = nn.Flatten(1)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(6000, layer_size) \n",
    "        \n",
    "        if num_layers == 2:\n",
    "            self.feedforward = nn.Sequential(\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif num_layers == 3:\n",
    "            self.feedforward = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_size, layer_size),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif num_layers == 4:\n",
    "            self.feedforward = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_size, layer_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_size, layer_size),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "       \n",
    "        self.fc2 = nn.Linear(layer_size, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.conv(x)\n",
    "        output = self.relu(output)\n",
    "        output = self.flat(output)\n",
    "        output = self.drop(output)\n",
    "        output = self.fc1(output)\n",
    "        output = self.feedforward(output)\n",
    "        output = self.fc2(output)   \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2D, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(200,100,kernel_size=1,padding='same') \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(100,100,kernel_size=1,padding='same') \n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.flat = nn.Flatten(1)\n",
    "        self.drop = nn.Dropout(p=0.1)\n",
    "\n",
    "        self.fc1 = nn.Linear(400, 100)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool1(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "    \n",
    "        output = self.flat(output)\n",
    "        output = self.drop(output)\n",
    "        \n",
    "        output = self.fc1(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, Y, learning_rate=0.005, num_epochs=100):\n",
    "    dataset = torch.utils.data.TensorDataset(X, Y)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=None,\n",
    "            sampler=torch.utils.data.BatchSampler(torch.utils.data.RandomSampler(dataset), batch_size=100000, drop_last=False))\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    model.train();\n",
    "\n",
    "    loss_history = []\n",
    "    for _ in tqdm.trange(num_epochs):\n",
    "            for _, (inputs, targets) in enumerate(data_loader):\n",
    "                    optimizer.zero_grad()\n",
    "                    y_pred = model(inputs)\n",
    "                    loss = criterion(y_pred, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    loss_history.append(loss.item())\n",
    "                    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X, Y):\n",
    "    model.eval();\n",
    "    y_pred = model(X) # GIVES ALL NAN :(\n",
    "\n",
    "    length = len(y_pred)\n",
    "    results = np.zeros((length,2))\n",
    "    target  = np.zeros((length,2))\n",
    "    for i in range(length):\n",
    "        target[i,:]  = Y[i].detach().numpy()\n",
    "        results[i,:] = y_pred[i].detach().numpy()\n",
    "            \n",
    "    error = np.divide((target - results),target)    \n",
    "    _, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "    axs[0].plot(error[:,0])\n",
    "    axs[1].plot(error[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data for CNN\n",
    "# Use data 300ms long in 20ms intervals\n",
    "# Input  -- (num_segments,98,300) OR 300,98???\n",
    "# Output -- (deltaX, deltaY)\n",
    "\n",
    "# Spikes  -- trials[:,:][1] -- (98, length)\n",
    "# HandPos -- trials[:,:][2] -- (3,  length)\n",
    "\n",
    "training = trials[:75,:]\n",
    "testing  = trials[75:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_X = []\n",
    "training_Y = []\n",
    "for i in range(75):\n",
    "    for j in range(8):\n",
    "        spikes  = training[i,j][1]\n",
    "        handpos = training[i,j][2]\n",
    "        for n in range(int(np.floor((spikes.shape[1]-300)/20))):\n",
    "            training_X.append(spikes[:,n*20:n*20+300])\n",
    "            training_Y.append(((handpos[1,n*20+299]-handpos[1,n*20])*100, (handpos[2,n*20+299]-handpos[2,n*20])*100))\n",
    "\n",
    "training_X = torch.FloatTensor(training_X)\n",
    "training_Y = torch.FloatTensor(training_Y)\n",
    "\n",
    "testing_X = []\n",
    "testing_Y = []\n",
    "for i in range(25):\n",
    "    for j in range(8):\n",
    "        spikes  = testing[i,j][1]\n",
    "        handpos = testing[i,j][2]\n",
    "        for n in range(int(np.floor((spikes.shape[1]-300)/20))):\n",
    "            testing_X.append(spikes[:,n*20:n*20+300])\n",
    "            testing_Y.append(((handpos[1,n*20+299]-handpos[1,n*20])*100, (handpos[2,n*20+299]-handpos[2,n*20])*100))\n",
    "\n",
    "testing_X = torch.FloatTensor(testing_X)\n",
    "testing_Y = torch.FloatTensor(testing_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [34:32<00:00, 20.72s/it]\n"
     ]
    }
   ],
   "source": [
    "feedforward = FeedForward(3,20)\n",
    "feedforward = train_model(feedforward, training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model(feedforward, training_X, training_Y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
