{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "data = scio.loadmat('../monkeydata_training.mat')\n",
    "trials = data['trial'].reshape(100,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_fr(spike_data):\n",
    "    [_,len_data] = spike_data.shape\n",
    "    \n",
    "    avg_fr = sum(np.transpose(spike_data))\n",
    "    avg_fr = avg_fr / len_data\n",
    "    return avg_fr\n",
    "\n",
    "def calculate_design_matrix(spike_data, training_size):\n",
    "    design_mat  = np.zeros((training_size*8,4,98))\n",
    "    temp = 0\n",
    "    \n",
    "    for i in range(training_size):\n",
    "        for j in range(8):\n",
    "            design_mat[temp,0,:] = average_fr(spike_data[i,j][1][:,:])\n",
    "            design_mat[temp,1,:] = average_fr(spike_data[i,j][1][:,1:300])\n",
    "            design_mat[temp,2,:] = average_fr(spike_data[i,j][1][:,301:-100])\n",
    "            design_mat[temp,3,:] = average_fr(spike_data[i,j][1][:,-99:])\n",
    "            temp += 1\n",
    "               \n",
    "    return design_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spike data, fr = firing rate\n",
    "# Each trial: fr_avg, fr_planning, fr_moving, fr_end --> (trials,4,98)\n",
    "design_mat = calculate_design_matrix(trials,80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN - Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,num_layers,layer_size,dropout):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1  = nn.Linear(98, layer_size) \n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "        \n",
    "        if num_layers == 2:\n",
    "            self.feedforward = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        elif num_layers == 3:\n",
    "            self.feedforward = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_size, layer_size),\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif num_layers == 4:\n",
    "            self.feedforward = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_size, layer_size),\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_size, layer_size),\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "       \n",
    "        self.fc2 = nn.Linear(layer_size, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = self.drop(output)\n",
    "        output = self.feedforward(output)\n",
    "        output = self.fc2(output)   \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2D, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(200,100,kernel_size=1,padding='same') \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(100,100,kernel_size=1,padding='same') \n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.flat = nn.Flatten(1)\n",
    "        self.drop = nn.Dropout(p=0.1)\n",
    "\n",
    "        self.fc1 = nn.Linear(400, 100)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool1(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "    \n",
    "        output = self.flat(output)\n",
    "        output = self.drop(output)\n",
    "        \n",
    "        output = self.fc1(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, Y, learning_rate=0.01, num_epochs=500):\n",
    "        X = torch.FloatTensor(X)\n",
    "        Y = torch.FloatTensor(Y)\n",
    "        \n",
    "        dataset = torch.utils.data.TensorDataset(X, Y)\n",
    "        data_loader = torch.utils.data.DataLoader(dataset, batch_size=None,\n",
    "                sampler=torch.utils.data.BatchSampler(torch.utils.data.RandomSampler(dataset), batch_size=100000, drop_last=False))\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        model.train();\n",
    "\n",
    "        loss_history = []\n",
    "        for _ in tqdm.trange(num_epochs):\n",
    "                for _, (inputs, targets) in enumerate(data_loader):\n",
    "                        optimizer.zero_grad()\n",
    "                        y_pred = model(inputs)\n",
    "                        loss = criterion(y_pred, targets)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        loss_history.append(loss.item()/100)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_history)\n",
    "                        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X, Y):\n",
    "    X = torch.FloatTensor(X)\n",
    "    Y = torch.FloatTensor(Y)\n",
    "    \n",
    "    model.eval();\n",
    "    y_pred = model(X) \n",
    "\n",
    "    length = len(y_pred)\n",
    "    results = np.zeros((length,2))\n",
    "    target  = np.zeros((length,2))\n",
    "    for i in range(length):\n",
    "        target[i,:]  = Y[i].detach().numpy()\n",
    "        results[i,:] = y_pred[i].detach().numpy()\n",
    "            \n",
    "    error_x = abs(target[:,0] - results[:,0])/100\n",
    "    error_y  = abs(target[:,1] - results[:,1])/100\n",
    "    \n",
    "    plt.figure()\n",
    "    _, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "    axs[0].plot(error_x)\n",
    "    axs[0].title.set_text('X - error')\n",
    "    axs[1].plot(error_y)\n",
    "    axs[1].title.set_text('Y - error')\n",
    "    \n",
    "    print('x: ' + str(np.mean(error_x)))\n",
    "    print('y: ' + str(np.mean(error_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data for CNN\n",
    "# Use data 300ms long in 20ms intervals\n",
    "# Input  -- (num_segments,98,300) OR 300,98???\n",
    "# Output -- (deltaX, deltaY)\n",
    "\n",
    "# Spikes  -- trials[:,:][1] -- (98, length)\n",
    "# HandPos -- trials[:,:][2] -- (3,  length)\n",
    "\n",
    "training = trials[:80,:]\n",
    "testing  = trials[80:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with raw data\n",
    "training_X = []\n",
    "training_Y = []\n",
    "for i in range(75):\n",
    "    for j in range(8):\n",
    "        spikes  = training[i,j][1]\n",
    "        handpos = training[i,j][2]\n",
    "        for n in range(int(np.floor((spikes.shape[1]-300)/20))):\n",
    "            training_X.append(spikes[:,n*20:n*20+300])\n",
    "            training_Y.append(((handpos[1,n*20+299]-handpos[1,n*20])*100, (handpos[2,n*20+299]-handpos[2,n*20])*100))\n",
    "\n",
    "training_X = torch.FloatTensor(training_X)\n",
    "training_Y = torch.FloatTensor(training_Y)\n",
    "\n",
    "testing_X = []\n",
    "testing_Y = []\n",
    "for i in range(25):\n",
    "    for j in range(8):\n",
    "        spikes  = testing[i,j][1]\n",
    "        handpos = testing[i,j][2]\n",
    "        for n in range(int(np.floor((spikes.shape[1]-300)/20))):\n",
    "            testing_X.append(spikes[:,n*20:n*20+300])\n",
    "            testing_Y.append(((handpos[1,n*20+299]-handpos[1,n*20])*100, (handpos[2,n*20+299]-handpos[2,n*20])*100))\n",
    "\n",
    "testing_X = torch.FloatTensor(testing_X)\n",
    "testing_Y = torch.FloatTensor(testing_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with firing rate\n",
    "training_X = []\n",
    "training_Y = []\n",
    "testing_X = []\n",
    "testing_Y = []\n",
    "\n",
    "for j in range(8):\n",
    "    X_train_direction = []\n",
    "    Y_train_direction = []\n",
    "    X_test_direction = []\n",
    "    Y_test_direction = []\n",
    "    \n",
    "    for i in range(80):\n",
    "        [_, spikes, handpos] = training[i,j]\n",
    "       \n",
    "        for n in range(0,spikes.shape[1]-300,20):\n",
    "            X_train_direction.append(average_fr(spikes[:,n:n+300])) \n",
    "            Y_train_direction.append(((handpos[1,n+299]-handpos[1,n+279])*100, (handpos[2,n+299]-handpos[2,n+279])*100))\n",
    "    \n",
    "    for i in range(20):\n",
    "        [_, spikes, handpos] = testing[i,j]\n",
    "        \n",
    "        for n in range(0,spikes.shape[1]-300,20):\n",
    "            X_test_direction.append(average_fr(spikes[:,n:n+300]))\n",
    "            Y_test_direction.append(((handpos[1,n+299]-handpos[1,n+279])*100, (handpos[2,n+299]-handpos[2,n+279])*100))\n",
    "     \n",
    "    training_X.append(X_train_direction)\n",
    "    training_Y.append(Y_train_direction)\n",
    "    testing_X.append(X_test_direction)\n",
    "    testing_Y.append(Y_test_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 4708/8000 [00:05<00:03, 866.75it/s]"
     ]
    }
   ],
   "source": [
    "## Create 8 models!\n",
    "for i in range (8):\n",
    "    feedforward = FeedForward(2,15,0.6)\n",
    "    feedforward = train_model(feedforward, training_X[i], training_Y[i], 0.002, 8000)\n",
    "    test_model(feedforward, testing_X[i], testing_Y[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
